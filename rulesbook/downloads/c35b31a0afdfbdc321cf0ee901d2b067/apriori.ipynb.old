{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apriori Algorithm",
   "id": "37de764d5361188a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:42:13.319599Z",
     "start_time": "2025-02-17T17:42:13.315845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to count the frequency of itemsets in the transactions\n",
    "def count_itemsets(transactions, itemsets):\n",
    "    itemset_counts = {itemset: 0 for itemset in itemsets}\n",
    "    for transaction in transactions:\n",
    "        for itemset in itemsets:\n",
    "            if set(itemset).issubset(set(transaction)):\n",
    "                itemset_counts[itemset] += 1\n",
    "    return itemset_counts\n"
   ],
   "id": "1b729d12802ad199",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:42:13.554297Z",
     "start_time": "2025-02-17T17:42:13.549949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to generate candidate itemsets from previous frequent itemsets\n",
    "def generate_candidates(prev_frequent_itemsets, k):\n",
    "    candidates = set()\n",
    "    prev_frequent_itemsets = list(prev_frequent_itemsets)  # convert to list for indexing\n",
    "    for i in range(len(prev_frequent_itemsets)):\n",
    "        for j in range(i + 1, len(prev_frequent_itemsets)):\n",
    "            # Join two itemsets if their first k-1 items are the same\n",
    "            itemset1, itemset2 = prev_frequent_itemsets[i], prev_frequent_itemsets[j]\n",
    "            candidate = tuple(sorted(set(itemset1).union(set(itemset2))))\n",
    "            if len(candidate) == k:  # Only keep itemsets of length k\n",
    "                candidates.add(candidate)\n",
    "    return candidates\n",
    "\n"
   ],
   "id": "877aa2e9bde68ce",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:42:13.772298Z",
     "start_time": "2025-02-17T17:42:13.767558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# Helper function to generate rules from frequent itemsets\n",
    "def generate_rules(frequent_itemsets, itemset_counts, min_confidence, total_transactions):\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            # Generate all non-empty subsets of itemset\n",
    "            for size in range(1, len(itemset)):\n",
    "                for antecedent in combinations(itemset, size):\n",
    "                    antecedent = tuple(sorted(antecedent))  # sort to keep consistency\n",
    "                    consequent = tuple(sorted(set(itemset) - set(antecedent)))\n",
    "\n",
    "                    # Calculate confidence of the rule: support(X âˆª Y) / support(X)\n",
    "                    antecedent_support = itemset_counts.get(antecedent, 0) / total_transactions\n",
    "                    rule_support = itemset_counts.get(itemset, 0) / total_transactions\n",
    "\n",
    "                    if antecedent_support > 0:\n",
    "                        confidence = rule_support / antecedent_support\n",
    "                        if confidence >= min_confidence:\n",
    "                            rules.append((antecedent, consequent, confidence))\n",
    "    return rules\n"
   ],
   "id": "f97030ed6f66abfb",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:42:14.092999Z",
     "start_time": "2025-02-17T17:42:14.086905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main Apriori function\n",
    "def apriori(transactions, min_support, min_confidence):\n",
    "    # Convert transactions to list of sets for easier subset checking\n",
    "    transactions = [set(transaction) for transaction in transactions]\n",
    "\n",
    "    # Step 1: Generate candidate 1-item itemsets\n",
    "    all_items = set(item for transaction in transactions for item in transaction)\n",
    "    candidate_1_itemsets = [(item,) for item in all_items]\n",
    "\n",
    "    # Step 2: Count 1-item itemsets and prune by minimum support\n",
    "    itemset_counts = count_itemsets(transactions, candidate_1_itemsets)\n",
    "    frequent_itemsets = [itemset for itemset, count in itemset_counts.items() if\n",
    "                         count / len(transactions) >= min_support]\n",
    "\n",
    "    # Step 3: Generate higher-order itemsets\n",
    "    k = 2\n",
    "    all_frequent_itemsets = frequent_itemsets.copy()  # Store all frequent itemsets\n",
    "    all_itemset_counts = {**itemset_counts}\n",
    "    while frequent_itemsets:\n",
    "        candidate_k_itemsets = generate_candidates(frequent_itemsets, k)\n",
    "        itemset_counts = count_itemsets(transactions, candidate_k_itemsets)\n",
    "        frequent_itemsets = [itemset for itemset, count in itemset_counts.items() if\n",
    "                             count / len(transactions) >= min_support]\n",
    "\n",
    "        # Add the frequent itemsets of this size to the result\n",
    "        all_frequent_itemsets.extend(frequent_itemsets)\n",
    "        all_itemset_counts = {**all_itemset_counts, **itemset_counts}\n",
    "        k += 1\n",
    "\n",
    "    # Step 4: Generate association rules\n",
    "    rules = generate_rules(all_frequent_itemsets, all_itemset_counts, min_confidence, len(transactions))\n",
    "\n",
    "    return all_frequent_itemsets, rules\n"
   ],
   "id": "397ff19ca5813684",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:42:44.098309Z",
     "start_time": "2025-02-17T17:42:44.093471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_support = 0.5\n",
    "min_confidence = 1.0\n",
    "\n",
    "transactions = [('eggs', 'bacon', 'soup'),\n",
    "                ('eggs', 'bacon', 'apple'),\n",
    "                ('soup', 'bacon', 'banana')]\n",
    "frequent_itemsets, rules = apriori(transactions, min_support, min_confidence)\n",
    "print(rules)"
   ],
   "id": "fd44065f316d03a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('eggs',), ('bacon',), 1.0), (('soup',), ('bacon',), 1.0)]\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:42:44.894153Z",
     "start_time": "2025-02-17T17:42:44.890468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from efficient_apriori import apriori as ap2\n",
    "\n",
    "frequent_itemsets2, rules2 = ap2(transactions, min_support=0.5, min_confidence=1)\n",
    "print(rules2)"
   ],
   "id": "a131aa98a9616918",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{eggs} -> {bacon}, {soup} -> {bacon}]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34ae664554a924e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
