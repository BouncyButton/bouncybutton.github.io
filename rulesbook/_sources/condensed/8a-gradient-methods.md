# Gradient methods

Now, we explore a couple of implementations:

* MLLP (Multi-Layer Logical Perceptron) provides the most straightforward implementation of rule-based models in a differentiable architecture.
* RRL (Rule-representation Learner) extends the previous work by introducing a linear layer to learn weighted rules.

